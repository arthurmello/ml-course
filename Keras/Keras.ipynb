{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabad705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.7.0\n",
    "#!pip uninstall pydot\n",
    "#!pip uninstall pydotplus\n",
    "#!pip uninstall graphviz\n",
    "\n",
    "#!pip install pydot\n",
    "#!pip install pydotplus\n",
    "#!conda install -c anaconda graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cedf1d7",
   "metadata": {},
   "source": [
    "# Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad659609",
   "metadata": {},
   "source": [
    "## Exemple 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge les données\n",
    "dataset = loadtxt('data.csv', delimiter=',')\n",
    "\n",
    "# split input et output\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65b444",
   "metadata": {},
   "source": [
    "Déscription du dataset : https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad59e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition du modèle\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=###, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(###, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on compile le modèle\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# on entraîne le modèle avec nos données\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# évaluation du modèle\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on calcule les probabilités\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# on fait des prévisions avec ces probabilités\n",
    "predictions = (model.predict(X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# résumé des 5 premiers exemples\n",
    "for i in range(5):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398356a",
   "metadata": {},
   "source": [
    "## Exemple 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Flatten(input_shape=(###, ###)),\n",
    "  Dense(###, activation=###),\n",
    "  Dropout(###),\n",
    "  Dense(###)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe75f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a849d3",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c21136",
   "metadata": {},
   "source": [
    "L'API \"Functional\" de Keras est plus flexible dans la définition des modèles.\n",
    "\n",
    "Plus spécifiquement, il nous permet de définir des modèles avec des \"inputs\" ou \"outputs\" multiples, ainsi que des modèles qui partagent des couches (\"shared layers\").\n",
    "\n",
    "Les modèles sont définis en créant les couches et en les connectant directement entre elles. Ensuite, on définit un modèle et on spécifie les couches qui seront utilisés comme \"input\" et \"output\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447f63b",
   "metadata": {},
   "source": [
    "## La définition des inputs\n",
    "Différement du modéle Sequential, on doit créer et définir une couche \"Input\" pour spécifier le format des données d'entrée.\n",
    "Pour définir ce format, on fournie un tuple à la couche d'entrée.\n",
    "\n",
    "Quand les données d'entrée sont multidimensionnelles, comme pour un Perceptron multi-couches, le format doit explicitement laisser de l'espace pour la taille du mini-batch, utilisé pour splitter les données lors de l'entraînement. Ainsi, le tuple est toujours défini avec une dérnière dimension vide quand l'input est uni-dimensionnel. Par exemple, (2,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(###,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1af5f4",
   "metadata": {},
   "source": [
    "## La connéction des couches\n",
    "Les couches sont connectées par paires.\n",
    "\n",
    "Cela est fait en spécifiant l'origine de l'input dès que l'on définit une nouvelle couche.\n",
    "\n",
    "Regardons un petit exemple. Nous créons l'input comme on l'a fait dans l'exemple précedent, et ensuite on crée une couche cachée en utilisant Dense, qui reçoit l'input de la couche input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = ###(shape=(###,))\n",
    "hidden = ###(2)(###)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173446bd",
   "metadata": {},
   "source": [
    "## La création du modèle\n",
    "Après avoir crée les couches du modèle et les avoir connectées, il faut définir le modèle.\n",
    "\n",
    "Dans Keras, il existe une classe \"Model\", utilisé pour créer un modèle à partir des couches. Il faut spécifier uniquement les couches d'entrée et de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = ###(shape=(###,))\n",
    "hidden = ###(2)(###)\n",
    "model = Model(inputs=###, outputs=###)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93fecc",
   "metadata": {},
   "source": [
    "## Standard Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b75fc",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron\n",
    "Regardons un modèle du type \"Multilayer Perceptron\" pour faire de la classification binaire.\n",
    "\n",
    "Le modèle a 10 inputs, 3 couches cachées avec 10, 20 e 10 neurons, et une couche de sorte avec 1 output. \n",
    "\n",
    "Pour chaque couche cachée, on utilise un fonction d'activation du type \"Unité Linéaire Rectifiée\" (ou ReLU), et une fonction d'activation du type \"Sigmoid\" pour la sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eae884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "visible = Input(shape=(###,))\n",
    "hidden1 = ###(###, activation='relu')(###)\n",
    "hidden2 = ###(###, activation='relu')(###)\n",
    "hidden3 = ###(###, activation='relu')(###)\n",
    "output = ###(###, activation='###')(###)\n",
    "model = Model(inputs=###, outputs=###)\n",
    "\n",
    "# summary du modèle\n",
    "print(model.summary())\n",
    "\n",
    "# graph\n",
    "plot_model(model, to_file='img/multilayer_perceptron_graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c394951a",
   "metadata": {},
   "source": [
    "### CNN\n",
    "Les CNN, ou réseaux de neurones convolutifs sont plus souvent utilisés pour la classification d'images.\n",
    "\n",
    "Le modèle prend en entrée des images en noir et blanc, de 64x64, et a une séquence de 2 couches convolutives et 2 couches de \"pooling\" pour l'extraction des features, suivies par une couche \"fully-connected\" (Dense) pour interpréter ces couches et une couche de sortie avec un fonction d'activation du type \"sigmoid\" pour une classification binaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "visible = Input(shape=(###,###,1))\n",
    "conv1 = Conv2D(32, kernel_size=4, activation='relu')(visible)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(###)\n",
    "conv2 = Conv2D(16, kernel_size=4, activation='relu')(###)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(###)\n",
    "flat = Flatten()(###)\n",
    "hidden1 = Dense(###, activation='relu')(###)\n",
    "output = Dense(###, activation='sigmoid')(###)\n",
    "model = Model(inputs=###, outputs=###)\n",
    "\n",
    "# summary du modèle\n",
    "print(model.summary())\n",
    "\n",
    "# graph\n",
    "plot_model(model, to_file='img/convolutional_neural_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707aff0e",
   "metadata": {},
   "source": [
    "### RNN\n",
    "Maintenant, nous alons créer un réseau de neurones récurrents du type LSTM (Long Short-Term Memory), pour classifier des séquences.\n",
    "\n",
    "Le modèle prend en entrée 100 steps d'une même feature. Le modèle a une seule couche LSTM cachée pour extraire des features de la séquence, suivie par une couche du type \"fully connected\" pour interpréter la sortie de la LSTM, suivie par une couhce de sortie pour des prédictions binaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d06d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "visible = Input(shape=(###,1))\n",
    "hidden1 = LSTM(###)(###)\n",
    "hidden2 = Dense(###, activation='###')(###)\n",
    "output = Dense(1, activation='###')(###)\n",
    "model = Model(inputs=###, outputs=###)\n",
    "\n",
    "# summary du modèle\n",
    "print(model.summary())\n",
    "              \n",
    "# graph\n",
    "plot_model(model, to_file='img/recurrent_neural_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e307cb5",
   "metadata": {},
   "source": [
    "### Shared Layers Model\n",
    "Plusieurs couches peuvent partager la sortie d'une couche.\n",
    "\n",
    "Par exemple, on peut avoir plusieurs couches d'extraction de features d'un même input, ou plusieurs couches pour interpréter la sortue d'une couche d'extraction de features.\n",
    "\n",
    "Regardons ces 2 exemples plus en détail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032277c",
   "metadata": {},
   "source": [
    "#### Shared input layer\n",
    "Nous alons créer plusieurs couches de convolution avec des kernels de différentes tailles pour interpréter un image.\n",
    "\n",
    "Le modèle prend des images en noir & blanc, et 64x64 pixels. Il y a 2 sub-modèles du type CNN d'extraction de features qui partagent cet input; le premier a un kernel de taille 4 et le 2ème un kernel de taille 8. Les sorties de ces submodèles d'extraction de features sont applatis en vecteurs et concatenés pour former un long vecteur, et après sont utilisés par une couche du type \"fully connected\" pour être interpretés avant qu'une couche finale de sortie fasse une classification binaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d43500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# input layer\n",
    "visible = ###(shape=(###,###,1))\n",
    "\n",
    "# 1er feature extractor\n",
    "conv1 = Conv2D(32, kernel_size=###, activation='relu')(visible)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "flat1 = Flatten()(pool1)\n",
    "\n",
    "# 2ème feature extractor\n",
    "conv2 = Conv2D(16, kernel_size=###, activation='relu')(visible)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "flat2 = Flatten()(pool2)\n",
    "\n",
    "# concatenation des \"feature extractors\"\n",
    "merge = concatenate([###, ###])\n",
    "\n",
    "# couche d'interprétation\n",
    "hidden1 = Dense(###, activation='relu')(###)\n",
    "\n",
    "# output\n",
    "output = Dense(###, activation='###')(hidden1)\n",
    "model = ###(inputs=###, outputs=###)\n",
    "\n",
    "# summary du modèle\n",
    "print(model.summary())\n",
    "\n",
    "# graph\n",
    "plot_model(model, to_file='img/shared_input_layer.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d3987",
   "metadata": {},
   "source": [
    "#### Shared Feature Extraction Layer\n",
    "Nous allons créer 2 sub-modèles parallels pour interpréter la sortie d'un extracteur de features, pour faire une classification de séquences.\n",
    "\n",
    "L'input du modèle est composé par 100 \"time steps\" d'une feature. Une couche LSTM avec 10 célules de mémore interprète cette séquence. Le premier modèle d'interprétation est une couche du type \"fully connected\"; le 2ème est un modèle profond de 3 couches. La sortie des 2 modèles d'interprétation sont concatenés pour former un long vecteur, qui est ensuite utilisé par la couche finale de sortie pour faire une classification binaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "visible = ###\n",
    "\n",
    "# feature extractor\n",
    "extract1 = ###\n",
    "\n",
    "# 1er modèle d'interpretation\n",
    "interp1 = ###\n",
    "\n",
    "# 2ème modèle d'interpretation\n",
    "interp11 = ###\n",
    "interp12 = ###\n",
    "interp13 = ###\n",
    "\n",
    "# concatenation des couches d'interprétation\n",
    "merge = ###\n",
    "\n",
    "# output\n",
    "output = ###\n",
    "model = ###\n",
    "\n",
    "# summary do modèle\n",
    "print(model.summary())\n",
    "\n",
    "# graph\n",
    "plot_model(model, to_file='img/shared_feature_extractor.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
